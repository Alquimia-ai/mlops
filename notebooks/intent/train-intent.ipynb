{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746d98ff-75fc-4177-a596-46ddb8ecc558",
   "metadata": {},
   "source": [
    "# Fine tune bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e83f33-ca47-4c79-9e89-c97842753f1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load dataset from downloads ðŸ“¥ðŸ“¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c12f0a-4b1a-4402-8b4a-75f873a2e14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.28.0 in /opt/app-root/lib/python3.9/site-packages (4.28.0)\n",
      "Requirement already satisfied: datasets in /opt/app-root/lib/python3.9/site-packages (2.14.5)\n",
      "Requirement already satisfied: evaluate in /opt/app-root/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: accelerate in /opt/app-root/lib/python3.9/site-packages (0.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.28.0) (4.66.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from transformers==4.28.0) (3.12.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.28.0) (2023.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.28.0) (6.0.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.28.0) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.28.0) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.28.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.28.0) (23.1)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from transformers==4.28.0) (2.31.0)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.9/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/app-root/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/app-root/lib/python3.9/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in /opt/app-root/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/app-root/lib/python3.9/site-packages (from accelerate) (1.13.1)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.28.0) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.28.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.28.0) (2023.7.22)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (68.1.0)\n",
      "Requirement already satisfied: wheel in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.38.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.28.0 datasets evaluate accelerate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7ff2a9-899b-45f7-8c29-dcca5549a5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>question</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-13T21:02:06.194361Z</td>\n",
       "      <td>195</td>\n",
       "      <td>2.511</td>\n",
       "      <td>Do you have shirts?</td>\n",
       "      <td>Inventory</td>\n",
       "      <td>2023-10-13T21:02:06.194370Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-13T21:02:10.562741Z</td>\n",
       "      <td>196</td>\n",
       "      <td>1.604</td>\n",
       "      <td>Do you have t-shirts?</td>\n",
       "      <td>Inventory</td>\n",
       "      <td>2023-10-13T21:02:10.562761Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-13T21:02:13.785399Z</td>\n",
       "      <td>197</td>\n",
       "      <td>2.348</td>\n",
       "      <td>I want to buy a short to go out for a party</td>\n",
       "      <td>Inventory</td>\n",
       "      <td>2023-10-13T21:02:13.785410Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-13T21:02:16.348390Z</td>\n",
       "      <td>198</td>\n",
       "      <td>1.652</td>\n",
       "      <td>I wanna buy a coffe mug</td>\n",
       "      <td>Inventory</td>\n",
       "      <td>2023-10-13T21:02:16.348404Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-13T21:02:20.943221Z</td>\n",
       "      <td>199</td>\n",
       "      <td>3.431</td>\n",
       "      <td>I want to complete my order</td>\n",
       "      <td>Checkout</td>\n",
       "      <td>2023-10-13T21:02:20.943231Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation_id  annotator                   created_at   id  lead_time  \\\n",
       "0            194          1  2023-10-13T21:02:06.194361Z  195      2.511   \n",
       "1            195          1  2023-10-13T21:02:10.562741Z  196      1.604   \n",
       "2            196          1  2023-10-13T21:02:13.785399Z  197      2.348   \n",
       "3            197          1  2023-10-13T21:02:16.348390Z  198      1.652   \n",
       "4            198          1  2023-10-13T21:02:20.943221Z  199      3.431   \n",
       "\n",
       "                                      question  sentiment  \\\n",
       "0                          Do you have shirts?  Inventory   \n",
       "1                        Do you have t-shirts?  Inventory   \n",
       "2  I want to buy a short to go out for a party  Inventory   \n",
       "3                      I wanna buy a coffe mug  Inventory   \n",
       "4                  I want to complete my order   Checkout   \n",
       "\n",
       "                    updated_at  \n",
       "0  2023-10-13T21:02:06.194370Z  \n",
       "1  2023-10-13T21:02:10.562761Z  \n",
       "2  2023-10-13T21:02:13.785410Z  \n",
       "3  2023-10-13T21:02:16.348404Z  \n",
       "4  2023-10-13T21:02:20.943231Z  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Assuming the file is in the current working directory\n",
    "df = pd.read_csv(\"labeled_dataset.csv\")\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c714855b-8eae-4822-ab2d-59f46c748958",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size= 0.2 ## Define the testing size for metrics\n",
    "number_of_labels= os.environ.get('number_labels') if os.environ.get('number_labels') is not None else 2\n",
    "label_column_name='sentiment'\n",
    "text_column_name=os.environ.get('prompt_column') if os.environ.get('prompt_column') is not None else 'question'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc7068f-7b68-4d34-83c1-3060e7e94221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of labels to be showed are: 2 with a label colum name: sentiment and a prompt column name: question (The test size is 0.2)\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of labels to be showed are: {} with a label colum name: {} and a prompt column name: {} (The test size is {})\".format(number_of_labels,label_column_name,text_column_name,test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c6b30-3c04-4693-bbb6-f4249e051824",
   "metadata": {},
   "source": [
    "## Define mappings \n",
    "\n",
    "Here you have to define a map so the model can be properly trained lets see an example\n",
    "\n",
    "```python\n",
    "category_to_label = {\n",
    "    'availability': 0,\n",
    "    'irrelevant': 1,\n",
    "    'post sale': 2,\n",
    "    'invoice':3,\n",
    "    'service':4,\n",
    "    'pricing':5,\n",
    "    'general':6,\n",
    "    'cancelation policy':7,\n",
    "    'cancel reservation':8\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfc3d0d-7d5e-418c-9b54-c0609aa38172",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For now the map is being defined within the notebook\n",
    "\n",
    "category_to_label={\n",
    " \"Inventory\":0,\n",
    " \"Checkout\":1\n",
    "}\n",
    "# Add the new 'label' column to the dataframe by mapping values from the 'category' column\n",
    "df['label'] = df[label_column_name].replace(category_to_label)\n",
    "df=df.drop('annotation_id',axis=1)\n",
    "df=df.drop('annotator',axis=1)\n",
    "df=df.drop('created_at',axis=1)\n",
    "df=df.drop('id',axis=1)\n",
    "df=df.drop('lead_time',axis=1)\n",
    "df=df.drop('updated_at',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7715447-cd95-419f-a985-bb490457f205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Inventory': 0, 'Checkout': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfab0f2b-d9c5-4474-b1cc-5cb543217eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do you have shirts?</td>\n",
       "      <td>Inventory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have t-shirts?</td>\n",
       "      <td>Inventory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want to buy a short to go out for a party</td>\n",
       "      <td>Inventory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question  sentiment  label\n",
       "0                          Do you have shirts?  Inventory      0\n",
       "1                        Do you have t-shirts?  Inventory      0\n",
       "2  I want to buy a short to go out for a party  Inventory      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44bcdc3-c6a4-4067-98bc-79f8df3a3012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_train,df_test=train_test_split(df,test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2812aeee-aa35-4ffc-ba6e-1466296c7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset=Dataset.from_pandas(df_train)\n",
    "test_dataset=Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b8f309-1946-48c2-a16c-0965ab400919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name='distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c52911-84cf-4c1f-9370-7d9a591e4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[text_column_name],truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0704fc0d-5f1d-48d1-afd9-fafbd2740e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7cab79cda94af3adeebd87e6a661c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a9c4a75f1846af8a3051d315647bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test=test_dataset.map(preprocess_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f1409db-e337-4414-a23d-c03ecd4d30b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=number_of_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc1853b-bba9-4d4b-bb04-ed50abe1808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator=DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "353bdc9b-f4ad-45d2-980f-ea3c425ee679",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric= evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  logits,labels=eval_pred\n",
    "  predictions=np.argmax(logits,axis=-1)\n",
    "  return metric.compute(predictions=predictions,references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d39caf7-449e-4187-901a-0b435d3dbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=os.environ.get(\"model_name\") if os.environ.get(\"model_name\") is not None else \"medusa_retail_intent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b826f-e3fa-4d6d-9cb1-a1f205585698",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    hub_model_id=model_name,\n",
    "    output_dir=\"./output\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=tokenized_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8554c-e0de-4f83-9802-c5c0f35e41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.656800</td>\n",
       "      <td>0.353137</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.052877</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=0.19116783225908876, metrics={'train_runtime': 20.2182, 'train_samples_per_second': 7.419, 'train_steps_per_second': 0.989, 'total_flos': 649918174656.0, 'train_loss': 0.19116783225908876, 'epoch': 5.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fine tune model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02ecc9-314d-4ac3-80bc-cdd0bb815a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medusa_retail_intent\n"
     ]
    }
   ],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1dc20-5fcd-4f8d-9cc7-e39184bda1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save pytorch \n",
    "trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f537b1d6-2e21-4e44-ad88-1b96434045c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxoptimizer -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d38ae700-bde1-48f0-86d1-6dfc01d4286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import onnx\n",
    "import onnxoptimizer\n",
    "\n",
    "# Load the fine-tuned DistilBERT model and tokenizer\n",
    "model_checkpoint = model_name\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Create dummy input data for inference\n",
    "text = \"Do you have red t shirts?\"\n",
    "input_data = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "# Export the PyTorch model to ONNX\n",
    "onnx_path = \"model.onnx\"\n",
    "dummy_input = input_data[\"input_ids\"]\n",
    "torch.onnx.export(model, (dummy_input,), onnx_path, input_names=['input_ids'], output_names=['logits'])\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "\n",
    "# Optimize the ONNX model using onnxoptimizer\n",
    "optimized_model = onnxoptimizer.optimize(onnx_model)\n",
    "\n",
    "# Save the optimized ONNX model using file handling\n",
    "optimized_onnx_path = \"optimized_model.onnx\"\n",
    "with open(optimized_onnx_path, \"wb\") as f:\n",
    "    f.write(optimized_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17b18462-91a8-45c5-be83-c1939174e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the bucket and file path \n",
    "bucket_name =  os.environ.get('bucket_name') if os.environ.get('bucket_name') is not None else \"ecommerce-medusa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6699473a-0269-4012-a95c-5a783d8ec506",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AWS_ACCESS_KEY_ID & AWS_SECRET_ACCESS_KEY should be set as Env variables\n",
    "key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea6b6efc-acc7-44e2-b903-f7c4edf7c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import session\n",
    "session = boto3.session.Session(aws_access_key_id=key_id, aws_secret_access_key=secret_key)\n",
    "s3_client = boto3.client('s3', aws_access_key_id=key_id, aws_secret_access_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1b5a720-4620-486a-ac34-03d7783e7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload file to S3\n",
    "s3_client.upload_file('optimized_model.onnx', bucket_name, \"models/intent/\" + model_name + \"/\" +'model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "943c5e2c-cd92-4df0-8e82-a1587f5ba835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medusa_retail_intent pytorch has been deleted.\n",
      "ONNX model has been deleted.\n"
     ]
    }
   ],
   "source": [
    "## Delete directory in Jupyter Notebook\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Remove the local model directory\n",
    "shutil.rmtree(model_name)\n",
    "os.remove(\"optimized_model.onnx\")\n",
    "os.remove(\"model.onnx\")\n",
    "os.remove(\"labeled_dataset.csv\")\n",
    "shutil.rmtree(\"output\")\n",
    "\n",
    "print(f\"{model_name} pytorch has been deleted.\")\n",
    "print(\"ONNX model has been deleted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
